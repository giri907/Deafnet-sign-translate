# Deafnet-sign-translate
A digital platform/app designed to bridge the communication gap between the Deaf community and hearing individuals using sign language translation technology When technology listens with vision, even silence becomes powerful.
ğŸŒ Overview :-
DeafNet is an AI-powered Sign Language Translator built to connect the Deaf and Hearing worlds.
It uses Computer Vision, Deep Learning, and Natural Language Processing to translate sign language gestures into text and speech in real time.
Our mission is to make communication inclusive, effortless, and universal â€” ensuring that every individual, regardless of hearing ability, can be heard and understood.
âœ¨ Key Highlights:-
ğŸ–ï¸ Real-Time Sign Recognition
This is the core feature of DeafNet.
It uses a webcam and AI models (CNN + Mediapipe) to detect and recognize hand gestures in real time.
When a deaf user performs a sign (e.g., â€œHelloâ€, â€œThank Youâ€, â€œYesâ€, â€œNoâ€), the model instantly identifies it.
It works as if the camera can â€œsee and understandâ€ what the person is signing.
ğŸ’¬ Instant Text Translation
Once a gesture is recognized, it is immediately translated into readable text on the screen.
This allows hearing individuals to understand what the deaf person is communicating.
Itâ€™s extremely useful in real-life situations like classrooms, interviews, or emergency communication.
ğŸ”Š Speech Output (Optional)
This feature gives a voice to the deaf userâ€™s signs.
After a gesture is converted to text, the system uses Text-to-Speech (TTS) to generate spoken audio output.
It helps bridge the communication gap â€” others can literally hear what the deaf person is signing.
ğŸŒ Indian Sign Language (ISL) Support
DeafNet is initially trained and optimized for Indian Sign Language (ISL),
which is primarily used by the deaf community in India.
However, the system can be easily extended to support American Sign Language (ASL) or other sign languages in the future.
This makes the project inclusive and globally adaptable.
ğŸª¶ User-Friendly Interface
DeafNet is designed to be simple, intuitive, and accessible to users of all ages.
The GUI, built using Tkinter or Streamlit, provides an easy layout with clear buttons and live camera feed â€” no coding knowledge required.
The goal is to make advanced AI accessible to everyone.
ğŸ’¾ Offline Functionality
DeafNet can run without an active internet connection.
That means gesture recognition, translation, and speech output all work offline.
This makes it highly useful in rural areas, classrooms, defense environments, or any location with limited connectivity.
ğŸ§  Tech Stack
Category :- Technology
Language :- Python
Libraries :-OpenCV Â· TensorFlow/Keras Â· Mediapipe Â· NumPy Â· Tkinter
Tools :-Jupyter Notebook Â· VS Code
Model :-CNN (Convolutional Neural Network) for Gesture Recognition
Hardware :-Standard Webcam / Laptop Camera
âš™ï¸ Installation
1ï¸âƒ£ Clone the repository:- git clone https://github.com/giri907/Deafnet-sign-translate.git cd DeafNet
2ï¸âƒ£ Install dependencies :- pip install -r requirements.txt
3ï¸âƒ£ Run the application:- python app.py  or  open the Jupyter version:- jupyter notebook DeafNet.ipynb
ğŸš€ Future Plans
ğŸ¤– Add Emotion + Face Expression Detection
ğŸŒ Multilingual translation (English, Hindi, Bengali)
â˜ï¸ Deploy as a Streamlit / Flask Web App
ğŸ“± Android App integration using Flutter + TensorFlow Lite
ğŸ§  Model optimization for faster real-time prediction
ğŸ’– Why DeafNet?
Because communication should never depend on hearing.
Millions of Deaf individuals face daily challenges in expressing themselves.
DeafNet is built to change that â€” by letting AI understand and translate sign language instantly.
This isnâ€™t just a project.
Itâ€™s a step toward equality, empathy, and inclusion.


Developed By
Sunita Giri
email:- sunita005giri@gmail.com
Github:- https://github.com/giri907
